{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract electricity prices and volume from VENRON data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we use `Fonduer` to extract relations from the `VENRON` dataset.  \n",
    "This code is a modified version of their original hardware [tutorial](https://github.com/HazyResearch/fonduer-tutorials/tree/master/hardware).  \n",
    "The `Fonduer` pipeline (as outlined in the [paper](https://arxiv.org/abs/1703.05028)), and the iterative KBC process:\n",
    "\n",
    "1. KBC Initialization\n",
    "2. Candidate Generation and Multimodal Featurization\n",
    "3. Probabilistic Relation Classification\n",
    "4. Error Analysis and Iterative KBC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we import the relevant libraries and connect to the local database.  \n",
    "Follow the README instructions to setup the connection to the postgres DB correctly.\n",
    "\n",
    "If the database has existing candidates with generated features, the will not be overriden.  \n",
    "To re-run the entire pipeline including initialization drop the database first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dropdb -h postgres -h postgres --if-exists elec_price_vol\n",
    "! createdb -h postgres -h postgres elec_price_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PARALLEL = 4  # assuming a quad-core machine\n",
    "ATTRIBUTE = \"elec_price_vol\"\n",
    "DB_USERNAME = 'user'\n",
    "DB_PASSWORD = 'venron'\n",
    "conn_string = f'postgresql://{DB_USERNAME}:{DB_PASSWORD}@postgres:5432/{ATTRIBUTE}'\n",
    "    \n",
    "docs_path = 'data/gold/html/'\n",
    "pdf_path = 'data/gold/pdf/'\n",
    "gold_file = 'data/electricity_gold.csv'\n",
    "max_docs = 50 # 114\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parsing and Transforming the Input Documents into Unified Data Models\n",
    "\n",
    "We first initialize a `Meta` object, which manages the connection to the database automatically, and enables us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fonduer import Meta, init_logging\n",
    "\n",
    "# Configure logging for Fonduer\n",
    "init_logging(log_dir=\"logs\")\n",
    "\n",
    "session = Meta.init(conn_string).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser.models import Document, Sentence\n",
    "from fonduer.parser import Parser\n",
    "\n",
    "has_documents = session.query(Document).count() > 0\n",
    "\n",
    "if (not has_documents): \n",
    "    doc_preprocessor = HTMLDocPreprocessor(docs_path, max_docs=max_docs)\n",
    "    corpus_parser = Parser(session, structural=True, lingual=True, visual=True, pdf_path=pdf_path)\n",
    "    %time corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)\n",
    "    \n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Dividing the Corpus into Test and Train\n",
    "\n",
    "We'll split the documents 80/10/10 into train/dev/test splits. Note that here we do this in a non-random order to preserve the consistency and we reference the splits by 0/1/2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "ld   = len(docs)\n",
    "\n",
    "train_docs = set()\n",
    "dev_docs   = set()\n",
    "test_docs  = set()\n",
    "splits = (0.8, 0.9)\n",
    "data = [(doc.name, doc) for doc in docs]\n",
    "data.sort(key=lambda x: x[0])\n",
    "for i, (doc_name, doc) in enumerate(data):\n",
    "    if i < splits[0] * ld:\n",
    "        train_docs.add(doc)\n",
    "    elif i < splits[1] * ld:\n",
    "        dev_docs.add(doc)\n",
    "    else:\n",
    "        test_docs.add(doc)\n",
    "from pprint import pprint\n",
    "pprint([x.name for x in train_docs][0:5])\n",
    "print(f\"Number of documents split: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Mention Extraction, Candidate Extraction Multimodal Featurization\n",
    "\n",
    "Given the unified data model from Phase 1, `Fonduer` extracts relation\n",
    "candidates based on user-provided **matchers** and **throttlers**. Then,\n",
    "`Fonduer` leverages the multimodality information captured in the unified data\n",
    "model to provide multimodal features for each candidate.\n",
    "\n",
    "## 2.1 Mention Extraction & Candidate Generation\n",
    "\n",
    "1. Define mention classes\n",
    "2. Use matcher functions to define the format of potential mentions\n",
    "3. Define Mentionspaces (Ngrams)\n",
    "4. Run Mention extraction (all possible ngrams in the document, API [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/candidates.html#fonduer.candidates.MentionExtractor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "from fonduer.candidates.matchers import RegexMatchSpan, DictionaryMatch, LambdaFunctionMatcher, Intersect, Union\n",
    "from fonduer.candidates import MentionNgrams\n",
    "from fonduer.candidates import MentionExtractor \n",
    "from fonduer.candidates.models import Mention\n",
    "\n",
    "hasMentions = session.query(Mention).count() > 0\n",
    "\n",
    "# 1.) Mention subclasses\n",
    "Station = mention_subclass(\"Station\")\n",
    "Price = mention_subclass(\"Price\")\n",
    "\n",
    "### Dictionary of known stations ###\n",
    "stations_list = [\n",
    "    \"COB\",\n",
    "    \"MID COLUMBIA\",\n",
    "    \"PALO VERDE\",\n",
    "    \"MEAD\",\n",
    "    \"NP-15\",\n",
    "    \"SP-15\",\n",
    "    \"PJM - Western HUB\",\n",
    "\n",
    "    \"Cob\",\n",
    "    \"Palo\",\n",
    "    \"SP 15\",\n",
    "    \"NP 15\",\n",
    "    \"MidC\",\n",
    "    \"MeadMktplace\",\n",
    "    \"PJM\",\n",
    "\n",
    "    \"Mead/Marketplace\",\n",
    "    \"California-Oregon Border\",\n",
    "    \"California Northern Zone\",\n",
    "    \"California Southern Zone\",\n",
    "\n",
    "    \"California-Oregon Border (COB)\",\n",
    "    \"California Northern Zone (NP-15)\",\n",
    "    \"California Southern Zone (SP-15)\",\n",
    "    \"Palo Verde\",\n",
    "    \"Mid-Columbia\",\n",
    "    \"Mid Columbia\",\n",
    "]\n",
    "\n",
    "if (not hasMentions):\n",
    "\n",
    "    # 2.) Matcher functions\n",
    "    station_matcher = DictionaryMatch(d=stations_list)\n",
    "    price_matcher = RegexMatchSpan(rgx=r\"\\d{1,4}(\\.\\d{1,5})\", longest_match_only=False)\n",
    "\n",
    "    # 3.) Mention spaces (Ngrams)\n",
    "    station_ngrams = MentionNgrams(n_max=4)\n",
    "    price_ngrams = MentionNgrams(n_max=1)\n",
    "\n",
    "\n",
    "    # 4.) Mention extraction\n",
    "    mention_extractor = MentionExtractor(\n",
    "        session, [Station, Price], [station_ngrams, price_ngrams], [station_matcher, price_matcher]\n",
    "    )\n",
    "    docs = session.query(Document).order_by(Document.name).all()\n",
    "    mention_extractor.apply(docs, parallelism=PARALLEL)\n",
    "\n",
    "    \n",
    "print(f\"Total Mentions: {session.query(Mention).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Candidate Extraction\n",
    "\n",
    "1. Define Candidate Class\n",
    "2. Define trottlers to reduce the number of possible candidates\n",
    "3. Extract candidates (View the API for the CandidateExtractor on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/candidates.html#fonduer.candidates.MentionExtractor).)\n",
    "\n",
    "In the last part we specified that these `Candidates` belong to the training set by specifying `split=0`; recall that we're referring to train/dev/test as splits 0/1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "import re\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "from fonduer.candidates.models import candidate_subclass\n",
    "from fonduer.utils.visualizer import Visualizer\n",
    "\n",
    "\n",
    "# 1.) Define Candidate class\n",
    "StationPrice = candidate_subclass(\"StationPrice\", [Station, Price])\n",
    "\n",
    "has_candidates = session.query(StationPrice).filter(StationPrice.split == 0).count() > 0\n",
    "\n",
    "# 2.) DefineThrottlers\n",
    "def any_filter(c):\n",
    "    (station, price) = c\n",
    "    if 'volume' in get_head_ngrams(price):\n",
    "        return False\n",
    "    if 'date' in get_head_ngrams(price):\n",
    "        return False \n",
    "    if 'non firm' in get_head_ngrams(price):\n",
    "        return False \n",
    "    return True\n",
    "\n",
    "any_throttler = any_filter\n",
    "\n",
    "# 3.) Candidate extraction\n",
    "candidate_extractor = CandidateExtractor(session, [StationPrice], throttlers=[any_throttler])\n",
    "\n",
    "for i, docs in enumerate([train_docs, dev_docs, test_docs]):\n",
    "    if (not has_candidates):\n",
    "        candidate_extractor.apply(docs, split=i, parallelism=PARALLEL)\n",
    "    print(f\"Number of Candidates in split={i}: {session.query(StationPrice).filter(StationPrice.split == i).count()}\")\n",
    "\n",
    "train_cands = candidate_extractor.get_candidates(split = 0)\n",
    "dev_cands = candidate_extractor.get_candidates(split = 1)\n",
    "test_cands = candidate_extractor.get_candidates(split = 2)\n",
    "\n",
    "\n",
    "# 4.) Visualize some candidate for error analysis\n",
    "pprint(train_cands[0][2003])\n",
    "vis = Visualizer(pdf_path)\n",
    "\n",
    "# Display a candidate\n",
    "vis.display_candidates([train_cands[0][2003]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Multimodal Featurization\n",
    "Unlike dealing with plain unstructured text, `Fonduer` deals with richly formatted data, and consequently featurizes each candidate with a baseline library of multimodal features. \n",
    "\n",
    "### Featurize with `Fonduer`'s optimized Postgres Featurizer\n",
    "We now annotate the candidates in our training, dev, and test sets with features. The `Featurizer` provided by `Fonduer` allows this to be done in parallel to improve performance.\n",
    "\n",
    "View the API provided by the `Featurizer` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/features.html#fonduer.features.Featurizer).\n",
    "\n",
    "At the end of this phase, `Fonduer` has generated the set of candidates and the feature matrix. Note that Phase 1 and 2 are relatively static and typically are only executed once during the KBC process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fonduer.features import Featurizer\n",
    "\n",
    "featurizer = Featurizer(session, [StationPrice])\n",
    "\n",
    "# Training set\n",
    "%time featurizer.apply(split=0, train=True, parallelism=PARALLEL)\n",
    "%time F_train = featurizer.get_feature_matrices(train_cands)\n",
    "print(F_train[0].shape)\n",
    "\n",
    "# Dev set\n",
    "%time featurizer.apply(split=1, parallelism=PARALLEL)\n",
    "%time F_dev = featurizer.get_feature_matrices(dev_cands)\n",
    "print(F_dev[0].shape)\n",
    "\n",
    "# Test set\n",
    "%time featurizer.apply(split=2, parallelism=PARALLEL)\n",
    "%time F_test = featurizer.get_feature_matrices(test_cands)\n",
    "print(F_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Phase 3: Probabilistic Relation Classification\n",
    "In this phase, `Fonduer` applies user-defined **labeling functions**, which express various heuristics, patterns, and [weak supervision](http://hazyresearch.github.io/snorkel/blog/weak_supervision.html) strategies to label our data, to each of the candidates to create a label matrix that is used by our data programming engine.\n",
    "\n",
    "1. Load Gold Data\n",
    "\n",
    "--- \n",
    "\n",
    "Iterate the following steps\n",
    "\n",
    "2. Create labeling functions\n",
    "3. Apply labeling functions and measure accuracy of each LF (based on gold data).\n",
    "4. Build a generative model by combining the labeling functions\n",
    "5. Iterate on labeling function based on the models score\n",
    "\n",
    "---\n",
    "\n",
    "6. Finally build a descriminative model and test on the test set\n",
    "\n",
    "### 3.1) Loading Gold LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from fonduer.supervision.models import GoldLabel\n",
    "from electricity_utils import gold\n",
    "from fonduer.supervision import Labeler\n",
    "\n",
    "# 1.) Load the gold data\n",
    "docs = corpus_parser.get_documents()\n",
    "labeler = Labeler(session, [StationPrice])\n",
    "%time labeler.apply(docs=docs, lfs=[[gold]], table=GoldLabel, train=True, parallelism=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2) Creating Labeling Functions\n",
    "\n",
    "We have 3 states that we can return from a LF: `ABSTAIN`, `FALSE` or `TRUE`.\n",
    "\n",
    "A library of data model utilities\n",
    "which can be used to write labeling functions are outline in [Read the\n",
    "Docs](http://fonduer.readthedocs.io/en/stable/user/data_model_utils.html). \n",
    "\n",
    "### 3.3) Applying the Labeling Functions\n",
    "\n",
    "Next, we need to actually run the LFs over all of our training candidates, producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database. Note that this will delete any existing `Labels` and `LabelKeys` for this candidate set.\n",
    "\n",
    "View the API provided by the `Labeler` on [ReadTheDocs](https://fonduer.readthedocs.io/en/stable/user/supervision.html#fonduer.supervision.Labeler).\n",
    "\n",
    "We can also view statistics about the resulting label matrix.\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for.\n",
    "\n",
    "In addition, because we have already loaded the gold labels, we can view the emperical accuracy of these labeling functions when compared to our gold labels using the `analysis` module of [Snorkel](https://github.com/snorkel-team/snorkel)\n",
    "\n",
    "### 3.4) Build Generative Model\n",
    "\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other. To do so, we use [Snorkel](https://github.com/snorkel-team/snorkel)'s single-task label model.\n",
    "\n",
    "We then print out the marginal probabilities for each training candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.utils.data_model_utils import *\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "ABSTAIN = -1\n",
    "FALSE = 0\n",
    "TRUE = 1\n",
    "\n",
    "def dict_without_station(station):\n",
    "    return [v for v in stations_list if not v == station]\n",
    "\n",
    "# 2.) Create labeling functions \n",
    "@labeling_function()\n",
    "def LF_price_head(c):\n",
    "    return TRUE if 'price' in get_head_ngrams(c.price) else ABSTAIN\n",
    "\n",
    "# @labeling_function()\n",
    "# def LF_on_peak_head(c):\n",
    "#     return TRUE if 'on peak' in get_head_ngrams(c.price) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_peak_head(c):\n",
    "    return TRUE if 'peak' in get_head_ngrams(c.price) else ABSTAIN\n",
    "\n",
    "# @labeling_function()\n",
    "# def LF_off_peak_head(c):\n",
    "#     return FALSE if 'off peak' in get_head_ngrams(c.price) else ABSTAIN\n",
    "\n",
    "# @labeling_function()\n",
    "# def LF_firm_head(c):\n",
    "#     return TRUE if 'firm' in get_head_ngrams(c.price) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def LF_dollar_to_left(c):\n",
    "    return TRUE if '$' in get_left_ngrams(c.price, window=2) else ABSTAIN\n",
    "\n",
    "# @labeling_function()\n",
    "# def LF_same_table(c):\n",
    "#     return TRUE if same_table(c) else ABSTAIN\n",
    "\n",
    "# @labeling_function()\n",
    "# def LF_other_station_table(c):\n",
    "#     return FALSE if overlap(\n",
    "#         dict_without_station(c.station), \n",
    "#         list(get_aligned_ngrams(c.price))\n",
    "#     ) else ABSTAIN\n",
    "\n",
    "station_price_lfs = [\n",
    "     LF_price_head,\n",
    "#     LF_on_peak_head,\n",
    "     LF_peak_head,\n",
    "#     LF_off_peak_head,\n",
    "#     LF_firm_head,\n",
    "     LF_dollar_to_left,  \n",
    "#     LF_other_station_table,\n",
    "]\n",
    "\n",
    "# 3.) Apply the LFs on the training set\n",
    "labeler = Labeler(session, [StationPrice])\n",
    "%time labeler.apply(split=0, lfs=[station_price_lfs], train=True, clear=True, parallelism=PARALLEL)\n",
    "%time L_train = labeler.get_label_matrices(train_cands)\n",
    "print(f\"Labeling functions on train_cands not ABSTAIN: {L_train[0].shape[1]}\")\n",
    "\n",
    "# 4.) Evaluate their accuracy\n",
    "L_gold_train = labeler.get_gold_labels(train_cands, annotator='gold')\n",
    "# Sort LFs for LFAnalysis because LFAnalysis does not sort LFs,\n",
    "# while columns of L_train are sorted alphabetically already.\n",
    "sorted_lfs = sorted(station_price_lfs, key=lambda lf: lf.name)\n",
    "LFAnalysis(L=L_train[0], lfs=sorted_lfs).lf_summary(Y=L_gold_train[0].reshape(-1))\n",
    "\n",
    "# 5.) Build generative model\n",
    "gen_model = LabelModel(cardinality=2)\n",
    "%time gen_model.fit(L_train[0], n_epochs=500, log_freq=100)\n",
    "\n",
    "train_marginals = gen_model.predict_proba(L_train[0])\n",
    "plt.hist(train_marginals[:, TRUE], bins=20)\n",
    "plt.show()\n",
    "\n",
    "# Apply on dev-set\n",
    "labeler.apply(split=1, lfs=[station_price_lfs], clear=True, parallelism=PARALLEL)\n",
    "%time L_dev = labeler.get_label_matrices(dev_cands)\n",
    "\n",
    "L_gold_dev = labeler.get_gold_labels(dev_cands, annotator='gold')\n",
    "LFAnalysis(L=L_dev[0], lfs=sorted_lfs).lf_summary(Y=L_gold_dev[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L=L_dev[0], lfs=sorted_lfs).lf_summary(Y=L_gold_dev[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model \n",
    "\n",
    "Fonduer uses the machine learning framework [Emmental](https://github.com/SenWu/emmental) to support all model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emmental\n",
    "\n",
    "# Setup training config\n",
    "config = {\n",
    "    \"meta_config\": {\"verbose\": True},\n",
    "    \"model_config\": {\"model_path\": None, \"device\": 0, \"dataparallel\": False},\n",
    "    \"learner_config\": {\n",
    "        \"n_epochs\": 50,\n",
    "        \"optimizer_config\": {\"lr\": 0.001, \"l2\": 0.0},\n",
    "        \"task_scheduler\": \"round_robin\",\n",
    "    },\n",
    "    \"logging_config\": {\n",
    "        \"evaluation_freq\": 1,\n",
    "        \"counter_unit\": \"epoch\",\n",
    "        \"checkpointing\": False,\n",
    "        \"checkpointer_config\": {\n",
    "            \"checkpoint_metric\": {f\"{ATTRIBUTE}/{ATTRIBUTE}/train/loss\": \"min\"},\n",
    "            \"checkpoint_freq\": 1,\n",
    "            \"checkpoint_runway\": 2,\n",
    "            \"clear_intermediate_checkpoints\": True,\n",
    "            \"clear_all_checkpoints\": True,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "emmental.init(Meta.log_path)\n",
    "emmental.Meta.update_config(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect word counter from training data\n",
    "from fonduer.learning.utils import collect_word_counter\n",
    "\n",
    "word_counter = collect_word_counter(train_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word embedding module for LSTM model\n",
    "# (in Logistic Regression, we generate it since Fonduer dataset requires word2id dict)\n",
    "from emmental.modules.embedding_module import EmbeddingModule\n",
    "\n",
    "arity = 2\n",
    "\n",
    "# Geneate special tokens\n",
    "specials = []\n",
    "for i in range(arity):\n",
    "    specials += [f\"~~[[{i}\", f\"{i}]]~~\"]\n",
    "\n",
    "emb_layer = EmbeddingModule(\n",
    "    word_counter=word_counter, word_dim=300, specials=specials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloader for training set\n",
    "from emmental.data import EmmentalDataLoader\n",
    "from fonduer.learning.dataset import FonduerDataset\n",
    "import numpy as np\n",
    "\n",
    "# Filter out noise samples\n",
    "diffs = train_marginals.max(axis=1) - train_marginals.min(axis=1)\n",
    "train_idxs = np.where(diffs > 1e-6)[0]\n",
    "\n",
    "train_dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict={ATTRIBUTE: \"labels\"},\n",
    "    dataset=FonduerDataset(\n",
    "        ATTRIBUTE,\n",
    "        train_cands[0],\n",
    "        F_train[0],\n",
    "        emb_layer.word2id,\n",
    "        train_marginals,\n",
    "        train_idxs,\n",
    "    ),\n",
    "    split=\"train\",\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emmental.model import EmmentalModel\n",
    "from fonduer.learning.task import create_task\n",
    "from emmental.learner import EmmentalLearner\n",
    "\n",
    "tasks = create_task(\n",
    "    ATTRIBUTE, 2, F_train[0].shape[1], 2, emb_layer, model=\"LogisticRegression\"\n",
    ")\n",
    "\n",
    "model = EmmentalModel(name=f\"{ATTRIBUTE}_task\")\n",
    "\n",
    "for task in tasks:\n",
    "    model.add_task(task)\n",
    "\n",
    "emmental_learner = EmmentalLearner()\n",
    "emmental_learner.learn(model, [train_dataloader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloader for test data\n",
    "test_dataloader = EmmentalDataLoader(\n",
    "    task_to_label_dict={ATTRIBUTE: \"labels\"},\n",
    "    dataset=FonduerDataset(\n",
    "        ATTRIBUTE, test_cands[0], F_test[0], emb_layer.word2id, 2\n",
    "    ),\n",
    "    split=\"test\",\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from electricity_utils import entity_level_f1 \n",
    "\n",
    "\n",
    "test_preds = model.predict(test_dataloader, return_preds=True)\n",
    "positive = np.where(np.array(test_preds[\"probs\"][ATTRIBUTE])[:, TRUE] > 0.6)\n",
    "true_pred = [test_cands[0][_] for _ in positive[0]]\n",
    "%time (TP, FP, FN) = entity_level_f1(true_pred, gold_file, ATTRIBUTE, test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
